---
title: "improve_feature_xgboost"
author: "Chun Zhai"
date: "November 6, 2018"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

---
title: "Untitled"
author: "Chun Zhai"
date: "10/24/2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

read the training and testing set
```{r}
library("xgboost")
library("EBImage")
library("abind")
library("gbm")
set.seed(2018)
setwd("~/Desktop/GitHub/Fall2018-Proj3-Sec2--sec2proj3_grp10")
getwd()
```


Provide directories for training images. Low-resolution (LR) image set and High-resolution (HR) image set will be in different subfolders. 
```{r}
train_dir <- train_dir <- "~/Desktop/GitHub/Fall2018-Proj3-Sec2--sec2proj3_grp10/data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
```

```{r}
run.cv=TRUE # run cross-validation on the training set
K <- 10  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
```


```{r model_setup}
model_values1 <- seq(3, 11, 2)
model_values2 <- seq(40, 60, 5)
```



```{r}
feature <- function(LR_dir, HR_dir, n_points=1000){
  
  ### Construct process features for training images (LR/HR pairs)
  
  ### Input: a path for low-resolution images + a path for high-resolution images 
  ###        + number of points sampled from each LR image
  ### Output: an .RData file contains processed features and responses for the images
  
  ### load libraries
  library("EBImage") 
  n_files <- 12 #length(list.files(LR_dir))
  
  ### store feature and responses
  featMat <- array(NA, c(n_files * n_points, 24, 3))
  labMat <- array(NA, c(n_files * n_points, 4, 3))
  
  ### read LR/HR image pairs
  
  for(i in 1:n_files){
    imgLR <- readImage(paste0(LR_dir,  "img_", sprintf("%04d", i), ".jpg"))
    imgHR <- readImage(paste0(HR_dir,  "img_", sprintf("%04d", i), ".jpg"))
    ### step 1. sample n_points from imgLR
    #t1 <- Sys.time()
        index.x <- sample(1:dim(imgLR)[2],n_points,replace = TRUE)
        index.y <- sample(1:dim(imgLR)[1],n_points,replace = TRUE)
    #t2 <- Sys.time()
    #print(paste("sample",t2-t1))
    ### step 2. for each sampled point in imgLR,
    
        ### step 2.1. save (the neighbor 8 pixels - central pixel) in featMat
        ###           tips: padding zeros for boundary points
        #pad zero
        b = array(0, dim=c(1,dim(imgLR)[2],3))
        c = array(0, dim=c((dim(imgLR)[1]+2),1,3))
        bimg = abind(b,imgLR,along=1)
        bimgb = abind(bimg,b,along=1)
        cbimgb = abind(c,bimgb,along=2)
        cbimgbc = abind(cbimgb,c,along=2)
        
        b_plus = array(0, dim=c(1,dim(imgLR)[2]+2,3))
        c_plus = array(0, dim=c((dim(imgLR)[1]+2+2),1,3))
        bcbimgbc = abind(b_plus,cbimgbc,along=1)
        bcbimgbcb = abind(bcbimgbc,b_plus,along=1)
        cbcbimgbcb = abind(c_plus,bcbimgbcb,along=2)
        cbcbimgbcbc = abind(cbcbimgbcb,c_plus,along=2)
        
    #t3 <- Sys.time()   
    #print(paste("pad",t3-t2))
        mat <- matrix(1:n_points, ncol = 1)
        func1 <- function(j){
          cbcbimgbcbc[(index.y[j]):(index.y[j]+4),(index.x[j]):(index.x[j]+4),]
        }
        points1 <- apply(mat,1,func1)
    #t4 <- Sys.time()
    #print(paste("9points",t4-t3))
        # neighbor 8 pixels - central pixel

        func2 <- function(k){
        allnei = points1[-c(13,38,63),k]
        allcen = points1[c(13,38,63),k]
        featmat = allnei - rep(allcen,c(24,24,24))
        }
        featmat <- apply(mat,1, func2)
    #t5 <- Sys.time()
    #print(paste("vectorize",t5-t4))
       ### step 2.2. save the corresponding 4 sub-pixels of imgHR in labMat
    imgHR <- imgHR@.Data
     func3 <- function(m){
      imgHR[(2*index.y[m]-1):(2*index.y[m]),(2*index.x[m]-1):(2*index.x[m]),]
     }
     points.hr <- apply(mat,1,func3)
     func4 <- function(k){
       newnei = points.hr[,k]
       allcen = points1[c(13,38,63),k]
       points.hr = newnei - rep(allcen,c(4,4,4))
     }
     points.hr <- apply(mat,1, func4)
    #t6 <- Sys.time()  
    #print(paste("hrpoints",t6-t5))
    ### step 3. repeat above for three channels
     
     featMat[(1+(i-1)*n_points):(n_points*i),,] <- array(t(featmat),dim=c(n_points,24,3))
     labMat[(1+(i-1)*n_points):(n_points*i),,] <-  array(t(points.hr),dim=c(n_points,4,3))
    
    #t7 <- Sys.time()
    #print(paste("toarray",t7-t6))
  }
  
  return(list(feature = featMat, label = labMat))
}

tm_feature_train <- NA
if(run.feature.train){
  tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
  feat_train <- dat_train$feature
  label_train <- dat_train$label
}
#save.image(file="../output/feature_train.RData")
dim(feat_train)
dim(label_train)
```


### Step 4: Train a regression model with training features and responses
Call the train model and test model from library. 

`train.R` and `test.R` should be wrappers for all your model training steps and your classification/prediction steps. 
+ `train.R`
  + Input: a path that points to the training set features and responses.
  + Output: an RData file that contains trained classifiers in the forms of R objects: models/settings/links to external trained configurations.
+ `test.R`
  + Input: a path that points to the test set features.
  + Input: an R object that contains a trained classifier.
  + Output: an R object of response predictions on the test set. If there are multiple classifiers under evaluation, there should be multiple sets of label predictions. 
```{r loadlib}
#source("../lib/train.R")
#source("../lib/test.R")
#load("/Users/peiluzhang/Documents/2018-fall-study/5243/proj3/label_train.RData")
#load("/Users/peiluzhang/Documents/2018-fall-study/5243/proj3/feat_train.RData")

#########################################################
### Train a classification model with training features ###
#########################################################

train <- function(dat_train, label_train, par=NULL){
  
  ### Train a Gradient Boosting Model (GBM) using processed features from training images
  
  ### Input: 
  ###  -  features from LR images 
  ###  -  responses from HR images
  ### Output: a list for trained models
  
  ### load libraries
  library("xgboost")
  
  ### creat model list
  modelList <- list()
  
  ### Train with gradient boosting model
 if(is.null(par)){
    depth <- 3
    nrounds <- 40
  } else {
    depth <- par$depth
    nrounds <- par$nrounds
  }
  
  ### the dimension of response arrat is * x 4 x 3, which requires 12 classifiers
  ### this part can be parallelized
  t1 <- Sys.time()
    
  for (i in 1:12){
    ## calculate column and channel
    c1 <- (i-1) %% 4 + 1
    c2 <- (i-c1) %/% 4 + 1
    featMat <- dat_train[, , c2]
    colnames(featMat) <- c("1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24")
    labMat <- label_train[, c1, c2]
    fit_xgb <- xgboost(data = featMat, 
                       label = labMat, 
                       eta = 0.1,
                       max_depth = depth, 
                       
                       nrounds = nrounds,
                       verbose = 0)
    modelList[[i]] <- list(fit=fit_xgb)
  }
   return(modelList)
}


```


```{r}
######################################################
### Fit the regression model with testing data ###
######################################################

### Author: Chengliang Tang
### Project 3

test <- function(modelList, dat_test){
  
  ### Fit the classfication model with testing data
  
  ### Input: 
  ###  - the fitted classification model list using training data
  ###  - processed features from testing images 
  ### Output: training model specification
  
  ### load libraries
  library("xgboost")
  
  predArr <- array(NA, c(dim(dat_test)[1], 4, 3))
  
  for (i in 1:12){
    fit_train <- modelList[[i]]
    ### calculate column and channel
    c1 <- (i-1) %% 4 + 1
    c2 <- (i-c1) %/% 4 + 1
    featMat <- dat_test[, , c2]
    ### make predictions
    predArr[, c1, c2] <- predict(fit_train$fit, newdata=featMat, 
                                  type="response")
  }
  return(predArr)
}
```

#### Model selection with cross-validation
* Do model selection by choosing among different values of training model parameters, that is, the interaction depth for GBM in this example. 
```{r runcv, message=FALSE, warning=FALSE, include=FALSE}
#source("../lib/cross_validation_xgboost.R")
########################
### Cross Validation ###
########################

### Author: Chengliang Tang
### Project 3

cv.function <- function(X.train, y.train, depth, nrounds, K){
  
  n <- dim(y.train)[1]
  n.fold <- floor(n/K)
  s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))  
  cv.error <- rep(NA, K)
  
  for (i in 1:K){
    train.data <- X.train[s != i, ,]
    train.label <- y.train[s != i, ,]
    test.data <- X.train[s == i, ,]
    test.label <- y.train[s == i, ,]
    
    par <- list(depth=depth, nrounds= nrounds)
    fit <- train(train.data, train.label, par)
    pred <- test(fit, test.data)  
    cv.error[i] <- mean((pred - test.label)^2)  
    
  }			
  return(c(mean(cv.error),sd(cv.error)))
}

if(run.cv){
  err_cv <- array(dim=c(length(model_values1)*length(model_values2), 2))
  for(k1 in 1:length(model_values1)){
    for(k2 in 1:length(model_values2)){ 
    cat("k1=", k1, ",k2=", k2, "\n")
    index <- (k1-1)*length(model_values2) + k2 
    err_cv[index,] <- cv.function(feat_train, label_train, model_values1[k1], model_values2[k2], K)
    }
  }

  #save(err_cv, file="../output/xgb_err_cv.RData")
}
```

* Choose the "best" parameter value
```{r}
err_cv  <- data.frame(err_cv)
colnames(err_cv) <- c("cv_mean","cv_sd")
par_mix <- expand.grid(model_values1, model_values2)

colnames(par_mix) <- c("K1","K2")
par_mix <- par_mix[order(par_mix$K1),]
err_cv  <- cbind(err_cv, par_mix)
plot(err_cv[,"K2"], err_cv[,1], xlab="model value combination", ylab="CV Error",
       main="Cross Validation Error", type="n", ylim=c(0.003, 0.005))
points(err_cv[,"K2"], err_cv[,1], col="blue", pch=16)
lines(err_cv[,"K2"], err_cv[,1], col="blue")
arrows(err_cv[,"K2"], err_cv[,1]-err_cv[,2], err_cv[,"K2"], err_cv[,1]+err_cv[,2], 
        length=0.1, angle=90, code=3)
```
```{r}
err_cv
```
```{r best_model}
model_best <- NULL 
if(run.cv){
  model_best <- err_cv[which.min(err_cv[,1]),]
}
par_best <- list(depth = model_best$K1, nrounds = model_best$K2)
par_best
```

* Train the model with the entire training set using the selected model (model parameter) via cross-validation.
```{r final_train, include=FALSE}
tm_train=NA
tm_train <- system.time(fit_train <- train(feat_train, label_train, par = par_best))
#save(fit_train, file="../output/fit_train_xgboost.RData")
```

```{r}
summary(fit_train[[1]]$fit)
```


### Step 5: Super-resolution for test images
Feed the final training model with the completely holdout testing data. 
+ `superResolution.R`
  + Input: a path that points to the folder of low-resolution test images.
  + Input: a path that points to the folder (empty) of high-resolution test images.
  + Input: an R object that contains tuned predictors.
  + Output: construct high-resolution versions for each low-resolution test image.
```{r superresolution}
#source("/Users/peiluzhang/Documents/2018-fall-study/5243/proj3/lib/superResolution.R")
test_dir <- "~/Desktop/GitHub/Fall2018-Proj3-Sec2--sec2proj3_grp10/data/test_set/" # This will be modified for different data sets.
test_LR_dir <- paste(test_dir, "LR/", sep="")
test_HR_dir <- paste(test_dir, "HR/", sep="")

tm_test=NA
if(run.test){
  #load(file="/Users/peiluzhang/Documents/2018-fall-study/5243/proj3/output/fit_train.RData")
  tm_test <- system.time(superResolution(test_LR_dir, test_HR_dir, fit_train))
}
tm_test
```

```{r}
########################
### Super-resolution ###
########################

### Author: Chengliang Tang
### Project 3

superResolution <- function(LR_dir, HR_dir, modelList){
  LR_dir = test_LR_dir
  HR_dir = test_HR_dir
  modelList = fit_train
  ### Construct high-resolution images from low-resolution images with trained predictor
  
  ### Input: a path for low-resolution images + a path for high-resolution images 
  ###        + a list for predictors

  ### load libraries 
  library("EBImage")
  n_files <- 12 #length(list.files(LR_dir))
  
  ### read LR/HR image pairs
  for(i in 1:n_files){
    imgLR <- readImage(paste0(LR_dir,  "img", "_", sprintf("%04d", i), ".jpg"))
    pathHR <- paste0(HR_dir,  "img", "_", sprintf("%04d", i), ".jpg")
    featMat <- array(NA, c(dim(imgLR)[1] * dim(imgLR)[2], 24, 3))
    
    ### step 1. for each pixel and each channel in imgLR:
    ###           save (the neighbor 8 pixels - central pixel) in featMat
    ###           tips: padding zeros for boundary points
        b = array(0, dim=c(1,dim(imgLR)[2],3))
        c = array(0, dim=c((dim(imgLR)[1]+2),1,3))
        bimg = abind(b,imgLR,along=1)
        bimgb = abind(bimg,b,along=1)
        cbimgb = abind(c,bimgb,along=2)
        cbimgbc = abind(cbimgb,c,along=2)
        
        b_plus = array(0, dim=c(1,dim(imgLR)[2]+2,3))
        c_plus = array(0, dim=c((dim(imgLR)[1]+2+2),1,3))
        bcbimgbc = abind(b_plus,cbimgbc,along=1)
        bcbimgbcb = abind(bcbimgbc,b_plus,along=1)
        cbcbimgbcb = abind(c_plus,bcbimgbcb,along=2)
        cbcbimgbcbc = abind(cbcbimgbcb,c_plus,along=2)
    #t3 <- Sys.time()   
    #print(paste("pad",t3-t2))
        index.x <- (1:dim(imgLR)[2])
        index.y <- (1:dim(imgLR)[1])
        index.all <- expand.grid(index.y,index.x)
       
        n_points = dim(imgLR)[1] * dim(imgLR)[2]
        mat <- matrix(1:n_points,ncol = 1)
        
        func1 <- function(j){
          cbcbimgbcbc[(index.all[j,1]):(index.all[j,1]+4),(index.all[j,2]):(index.all[j,2]+4),]
        }
        points1 <- apply(mat,1,func1)
       
        
        func2 <- function(k){
        allnei = points1[-c(13,38,63),k]
        allcen = points1[c(13,38,63),k]
        featmat = allnei - rep(allcen,c(24,24,24))
        }
        featmat <- apply(mat,1, func2)
        
        
        func3 <- function(m){
        allcen = points1[c(13,38,63),m]
        allcen = rep(allcen,c(4,4,4))
        }
        
        allcen <- apply(mat,1,func3)
        allcen <- t(allcen)
        
        
     featMat <- array(t(featmat),dim=c(n_points,24,3))
     
     
    ### step 2. apply the modelList over featMat
    predMat <- test(modelList, featMat)
    predMat[,,1] <- predMat[,,1] + allcen[,1:4]
    predMat[,,2] <- predMat[,,2] + allcen[,5:8]
    predMat[,,3] <-  predMat[,,3] + allcen[,9:12]
    
    predall <- array(NA,dim=c(dim(imgLR)[1]*2,dim(imgLR)[2]*2,3))
    dim(predall)
    for (k in 1:3){
      for (j in seq(from = 1, to = dim(imgLR)[2]*2,by = 2)){
        for (i in seq(from = 1, to = dim(imgLR)[1]*2,by = 2)){
          indexmat = ceiling(i/2)+(ceiling(j/2)-1)*dim(imgLR)[1]
          predall[(i:(i+1)),(j:(j+1)),k] <-rbind(predMat[indexmat,1:2,k],predMat[indexmat,3:4,k])
          }
             
      }
    }
    length(which(is.na(predall[,,1])))
    predall1 = Image(predall, colormode=Color)
    #display(predall1)
    
   
    ## following is not put into use currently
    
    ### step 3. recover high-resolution from predMat and save in HR_dir
    #save(predall, file="/Users/peiluzhang/Documents/2018-fall-study/5243/proj3/data/test_set/HR/img_0001.jpg")
    writeImage(imgLR, "~/Desktop/GitHub/Fall2018-Proj3-Sec2--sec2proj3_grp10/data/test_set/before1.jpeg")
    writeImage(predall1, "~/Desktop/GitHub/Fall2018-Proj3-Sec2--sec2proj3_grp10/data/test_set/after1.jpeg")

  }
}

```
### Summarize Running Time
Prediction performance matters, so does the running times for constructing features and for training the model, especially when the computation resource is limited. 
```{r running_time}
cat("Time for constructing training features=", tm_feature_train[1], "s \n")
# cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for super-resolution=", tm_test[1], "s \n")
```


